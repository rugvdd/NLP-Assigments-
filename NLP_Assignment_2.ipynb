{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "!pip install gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJoPqX17XeTV",
        "outputId": "bbb637ea-e2db-4e6d-b1a3-6822717b9397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Data\n",
        "data = [\n",
        "    \"the cat sat on the mat\",\n",
        "    \"the dog sat on the log\",\n",
        "    \"cats and dogs are great pets\"\n",
        "]"
      ],
      "metadata": {
        "id": "NTaLsc8YXvVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Bag of Words (Count Occurrence) ---\n",
        "count_vectorizer = CountVectorizer()\n",
        "bow_matrix = count_vectorizer.fit_transform(data)\n",
        "df_bow = pd.DataFrame(bow_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "t-ser4Q2XvZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. TF-IDF ---\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data)\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "30i5zh-lXvc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Word2Vec (Embeddings) ---\n",
        "# Word2Vec requires tokenized sentences\n",
        "tokenized_data = [sentence.split() for sentence in data]\n",
        "w2v_model = Word2Vec(sentences=tokenized_data, vector_size=10, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "DzWcbQf7XvgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look up a vector for a specific word\n",
        "vector_cat = w2v_model.wv['cat']"
      ],
      "metadata": {
        "id": "dLxUIK0zXvoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Display Results ---\n",
        "print(\"--- Bag of Words (Count) ---\")\n",
        "print(df_bow)\n",
        "print(\"\\n--- TF-IDF ---\")\n",
        "print(df_tfidf.round(3))\n",
        "print(\"\\n--- Word2Vec Vector for 'cat' (First 5 dims) ---\")\n",
        "print(vector_cat[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emRi62SWYDUy",
        "outputId": "b5103604-30dd-4791-b524-75603b2e1c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bag of Words (Count) ---\n",
            "   and  are  cat  cats  dog  dogs  great  log  mat  on  pets  sat  the\n",
            "0    0    0    1     0    0     0      0    0    1   1     0    1    2\n",
            "1    0    0    0     0    1     0      0    1    0   1     0    1    2\n",
            "2    1    1    0     1    0     1      1    0    0   0     1    0    0\n",
            "\n",
            "--- TF-IDF ---\n",
            "     and    are    cat   cats    dog   dogs  great    log    mat     on  \\\n",
            "0  0.000  0.000  0.428  0.000  0.000  0.000  0.000  0.000  0.428  0.325   \n",
            "1  0.000  0.000  0.000  0.000  0.428  0.000  0.000  0.428  0.000  0.325   \n",
            "2  0.408  0.408  0.000  0.408  0.000  0.408  0.408  0.000  0.000  0.000   \n",
            "\n",
            "    pets    sat   the  \n",
            "0  0.000  0.325  0.65  \n",
            "1  0.000  0.325  0.65  \n",
            "2  0.408  0.000  0.00  \n",
            "\n",
            "--- Word2Vec Vector for 'cat' (First 5 dims) ---\n",
            "[ 0.02348376 -0.04519032  0.08388732 -0.09858163  0.06764641]\n"
          ]
        }
      ]
    }
  ]
}